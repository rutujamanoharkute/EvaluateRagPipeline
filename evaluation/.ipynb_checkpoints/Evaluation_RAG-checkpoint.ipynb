{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5dd1dd-540d-41c8-a8ff-70ed243d7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b08b7bc-d64d-44a4-bee5-2adda833d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IndianFoodDatasetCSV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8136d4ab-f651-4c31-8692-8baa28d85e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Srno', 'RecipeName', 'TranslatedRecipeName', 'Ingredients',\n",
       "       'TranslatedIngredients', 'PrepTimeInMins', 'CookTimeInMins',\n",
       "       'TotalTimeInMins', 'Servings', 'Cuisine', 'Course', 'Diet',\n",
       "       'Instructions', 'TranslatedInstructions', 'URL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b516de2d-4798-46f1-964a-c27dccb0e366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evaluation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunConfig\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_pinecone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     context_precision,\n\u001b[1;32m      8\u001b[0m     faithfulness,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     answer_similarity\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluation'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.run_config import RunConfig\n",
    "from evaluation.query_pinecone import getrecommendedrecipes\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import streamlit as st\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "working_directory = os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "456f29ca-473d-428f-b12b-bc8471afeb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get response from ChatOpenAI\n",
    "def get_recipe_response(prompt):\n",
    "    chat_client = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    response = .chat_bot(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7860d62-41d7-4a90-ba2e-7ae202d3fa53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example question\u001b[39;00m\n\u001b[1;32m      2\u001b[0m recipe_question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow do I make a perfect butter chicken?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m recipe_response \u001b[38;5;241m=\u001b[39m \u001b[43mget_recipe_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe_question\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m recipe_answer \u001b[38;5;241m=\u001b[39m recipe_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m recipe_context \u001b[38;5;241m=\u001b[39m recipe_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintermediate_steps\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mget_recipe_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_recipe_response\u001b[39m(prompt):\n\u001b[1;32m      3\u001b[0m     chat_client \u001b[38;5;241m=\u001b[39m ChatOpenAI(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241m.\u001b[39mchat_bot(prompt)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "# Example question\n",
    "recipe_question = \"How do I make a perfect butter chicken?\"\n",
    "recipe_response = get_recipe_response(recipe_question)\n",
    "\n",
    "recipe_answer = recipe_response['output']\n",
    "recipe_context = recipe_response['intermediate_steps'][0][1]\n",
    "\n",
    "recipe_data = {\n",
    "    'question': [recipe_question],\n",
    "    'answer': [recipe_answer],\n",
    "    'contexts': [recipe_context],\n",
    "}\n",
    "recipe_dataset = Dataset.from_dict(recipe_data)\n",
    "recipe_score = evaluate(recipe_dataset, metrics=[faithfulness, answer_relevancy])\n",
    "recipe_score_df = recipe_score.to_pandas()\n",
    "\n",
    "# More recipe-related questions\n",
    "recipe_questions = [\n",
    "    \"Can you suggest a simple recipe for Paneer Tikka?\",\n",
    "    \"What's a good vegetarian dish for a party?\",\n",
    "    \"How can I make a quick and tasty pasta?\",\n",
    "    \"What are some traditional Indian desserts?\",\n",
    "    \"How to prepare a healthy salad?\",\n",
    "    \"Can you recommend a recipe for a refreshing summer drink?\",\n",
    "    \"What's a classic recipe for Dal Makhani?\",\n",
    "    \"How to make a delicious Biryani?\",\n",
    "    \"Can you suggest a recipe for a comforting soup?\",\n",
    "    \"What are some easy breakfast ideas?\"\n",
    "]\n",
    "\n",
    "all_recipe_answers = []\n",
    "all_recipe_contexts = []\n",
    "response_times = []\n",
    "\n",
    "# Iterating over the questions\n",
    "for question in recipe_questions:\n",
    "    start_time = time.time()\n",
    "    recipe_response = get_recipe_response(question)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    time_elapsed = end_time - start_time\n",
    "    \n",
    "    answer = recipe_response['output']\n",
    "    context = recipe_response['intermediate_steps'][0][1]\n",
    "    all_recipe_answers.append(answer)\n",
    "    all_recipe_contexts.append(context)\n",
    "    response_times.append(time_elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510432f3-06c5-4a76-9806-03c9e2d79bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing as a Dictionary\n",
    "recipe_data = {\n",
    "    'question': recipe_questions,\n",
    "    'answer': all_recipe_answers,\n",
    "    'contexts': all_recipe_contexts,\n",
    "}\n",
    "\n",
    "# Converting to a dataset for evaluation\n",
    "recipe_dataset = Dataset.from_dict(recipe_data)\n",
    "recipe_scores = evaluate(recipe_dataset, metrics=[faithfulness, answer_relevancy])\n",
    "recipe_metrics = recipe_scores.to_pandas()\n",
    "recipe_metrics['response_time'] = response_times\n",
    "\n",
    "# Plotting metrics\n",
    "metric_data = {\n",
    "    'query_index': [i for i in range(len(list(recipe_metrics['question'])))],\n",
    "    'relevancy': list(recipe_metrics['answer_relevancy']),\n",
    "    'response_time': list(recipe_metrics['response_time']),\n",
    "    'faithfulness': list(recipe_metrics['faithfulness'])\n",
    "}\n",
    "\n",
    "metric_df = pd.DataFrame(metric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf093a-73ef-4e57-8ef2-649e20216707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot for response time\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='query_index', y='response_time', data=metric_df, marker='o', label='Response Time')\n",
    "plt.xlabel('Query Index')\n",
    "plt.ylabel('Response Time (seconds)')\n",
    "plt.title('Response Time for Recipe Queries')\n",
    "plt.legend()\n",
    "plt.savefig(working_directory + \"/Images/response_time_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for relevancy and faithfulness\n",
    "metric_df_melted = metric_df.melt(id_vars='query_index', value_vars=['relevancy', 'faithfulness'], var_name='Metric', value_name='Value')\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.barplot(x='query_index', y='Value', hue='Metric', data=metric_df_melted)\n",
    "plt.xlabel('Query Index')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Relevancy and Faithfulness for Recipe Queries')\n",
    "plt.legend(title='Metric')\n",
    "plt.savefig(working_directory + \"/Images/relevancy_faithfulness_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Heatmap for correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlation_matrix = metric_df[['relevancy', 'response_time', 'faithfulness']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Recipe Metrics')\n",
    "plt.savefig(working_directory + \"/Images/correlation_matrix.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
